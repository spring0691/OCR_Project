{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import load_annoataion, check_and_validate_polys, crop_area, generate_rbox, get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_label(txt_root, image_list, img_name, index,\n",
    "                input_size=512, random_scale=np.array([0.5, 1, 2.0, 3.0]),\n",
    "                background_ratio=3. / 8):\n",
    "    '''\n",
    "    get image's corresponding matrix and ground truth\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        im_fn = image_list[index]\n",
    "        im_name = img_name[index]\n",
    "        im = cv2.imread(im_fn)\n",
    "        h, w, _ = im.shape\n",
    "        #txt_fn = im_name.replace(im_name.split('.')[1], 'txt')\n",
    "        #print(txt_fn)\n",
    "        if os.path.exists(txt_root + \"/\"+im_name[0:-4] + '.txt'):\n",
    "            txt_fn = im_name[0:-4] + '.txt'\n",
    "        elif os.path.exists(txt_root + \"/\"+im_name[0:-5] + '.txt'):\n",
    "            txt_fn = im_name[0:-5] + '.txt'\n",
    "        txt_fn = os.path.join(txt_root, txt_fn)\n",
    "\n",
    "        text_polys, text_tags = load_annoataion(txt_fn)\n",
    "        text_polys, text_tags = check_and_validate_polys(text_polys, text_tags, (h, w))\n",
    "        rd_scale = np.random.choice(random_scale)\n",
    "        im = cv2.resize(im, dsize=None, fx=rd_scale, fy=rd_scale)\n",
    "        text_polys *= rd_scale\n",
    "        # random crop a area from image\n",
    "        if np.random.rand() < background_ratio:\n",
    "            # crop background\n",
    "            im, text_polys, text_tags = crop_area(im, text_polys, text_tags, crop_background=True)\n",
    "            new_h, new_w, _ = im.shape\n",
    "            max_h_w_i = np.max([new_h, new_w, input_size])\n",
    "            im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8)\n",
    "            im_padded[:new_h, :new_w, :] = im.copy()\n",
    "            im = cv2.resize(im_padded, dsize=(input_size, input_size))\n",
    "            score_map = np.zeros((input_size, input_size), dtype=np.uint8)\n",
    "            geo_map_channels = 5\n",
    "            geo_map = np.zeros((input_size, input_size, geo_map_channels), dtype=np.float32)\n",
    "            training_mask = np.ones((input_size, input_size), dtype=np.uint8)\n",
    "        else:\n",
    "            im, text_polys, text_tags = crop_area(im, text_polys, text_tags, crop_background=False)\n",
    "            h, w, _ = im.shape\n",
    "\n",
    "            # pad the image to the training input size or the longer side of image\n",
    "            new_h, new_w, _ = im.shape\n",
    "            max_h_w_i = np.max([new_h, new_w, input_size])\n",
    "            im_padded = np.zeros((max_h_w_i, max_h_w_i, 3), dtype=np.uint8)\n",
    "            im_padded[:new_h, :new_w, :] = im.copy()\n",
    "            im = im_padded\n",
    "            new_h, new_w, _ = im.shape\n",
    "            resize_h = input_size\n",
    "            resize_w = input_size\n",
    "            im = cv2.resize(im, dsize=(resize_w, resize_h))\n",
    "            resize_ratio_3_x = resize_w / float(new_w)\n",
    "            resize_ratio_3_y = resize_h / float(new_h)\n",
    "            text_polys[:, :, 0] *= resize_ratio_3_x\n",
    "            text_polys[:, :, 1] *= resize_ratio_3_y\n",
    "            new_h, new_w, _ = im.shape\n",
    "            score_map, geo_map, training_mask = generate_rbox((new_h, new_w), text_polys, text_tags)\n",
    "\n",
    "        images = im[:, :, ::-1].astype(np.float32)\n",
    "        score_maps = score_map[::4, ::4, np.newaxis].astype(np.float32)\n",
    "        geo_maps = geo_map[::4, ::4, :].astype(np.float32)\n",
    "        training_masks = training_mask[::4, ::4, np.newaxis].astype(np.float32)\n",
    "\n",
    "    except Exception as e:\n",
    "        images, score_maps, geo_maps, training_masks = None, None, None, None\n",
    "\n",
    "    return images, score_maps, geo_maps, training_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'D:/_data/personal_project/ICDAR_2015/'\n",
    "train_img = root_path + 'train_img'\n",
    "train_txt = root_path + 'train_gt'\n",
    "\n",
    "image_list, img_name = get_images(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "261fa88f2c090dcd8643b3fd4649e492ba3c14c8e11d52777031b823fb316f84"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
